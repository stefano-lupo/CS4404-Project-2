{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, svm, preprocessing\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, precision_score, cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from util import (\n",
    "    readData,\n",
    "    createDesignMatrix,\n",
    "    createLabelVector,\n",
    "    printM,\n",
    "    splitData7030,\n",
    "    splitUpDataCrossVal,\n",
    "    featureNormalize,\n",
    "    multiclassToBinaryClass,\n",
    "    ACTIVE_DATASET,\n",
    "    TRAINING_PARAMS,\n",
    "    splitAndOverSample\n",
    ")\n",
    "\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "showPlots = False\n",
    "\n",
    "\n",
    "data = readData()\n",
    "X = createDesignMatrix(data)\n",
    "# X = featureNormalize(X)\n",
    "\n",
    "y = createLabelVector(data)\n",
    "y = np.squeeze(np.asarray(y))\n",
    "# y = np.array([1 if x>7 else 0 for x in y]);\n",
    "\n",
    "\n",
    "\n",
    "parameter_candidates_log_reg = [\n",
    "  {'C': [1, 10, 100]}\n",
    "]\n",
    "\n",
    "\n",
    "learning = True\n",
    "learnedVsDefault = {'learned': dict(), 'default': dict()}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1031), (6, 1608), (7, 622), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1024), (6, 1616), (7, 615), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1036), (6, 1639), (7, 602), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1064), (6, 1596), (7, 608), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1024), (6, 1606), (7, 626), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1002), (6, 1620), (7, 629), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1083), (6, 1591), (7, 590), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1029), (6, 1600), (7, 620), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1027), (6, 1585), (7, 639), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1075), (6, 1559), (7, 614), (8, 200), (9, 50)]\n",
      "Learning Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum C:  100\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1031), (6, 1608), (7, 622), (8, 200), (9, 50)]\n",
      "Using default LR Model\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1024), (6, 1616), (7, 615), (8, 200), (9, 50)]\n",
      "Using default LR Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1036), (6, 1639), (7, 602), (8, 200), (9, 50)]\n",
      "Using default LR Model\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1064), (6, 1596), (7, 608), (8, 200), (9, 50)]\n",
      "Using default LR Model\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1024), (6, 1606), (7, 626), (8, 200), (9, 50)]\n",
      "Using default LR Model\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1002), (6, 1620), (7, 629), (8, 200), (9, 50)]\n",
      "Using default LR Model\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1083), (6, 1591), (7, 590), (8, 200), (9, 50)]\n",
      "Using default LR Model\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1029), (6, 1600), (7, 620), (8, 200), (9, 50)]\n",
      "Using default LR Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/stefano/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1027), (6, 1585), (7, 639), (8, 200), (9, 50)]\n",
      "Using default LR Model\n",
      "Using OS Dict\n",
      "Oversampling\n",
      "Rating distribution:  [(3, 50), (4, 200), (5, 1075), (6, 1559), (7, 614), (8, 200), (9, 50)]\n",
      "Using default LR Model\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "\n",
    "  accuracies = []\n",
    "  kappas = []\n",
    "  micro = {'f1': [], 'precision': [], 'recall': []}\n",
    "  macro = {'f1': [], 'precision': [], 'recall': []}\n",
    "  k = 10\n",
    "\n",
    "  for i in range(k):\n",
    "\n",
    "    if k==1:\n",
    "      xTrain, yTrain, xVal, yVal = splitAndOverSample(X, y)\n",
    "    else:\n",
    "      xTrain, yTrain, xVal, yVal = splitAndOverSample(X, y, k, i)\n",
    "\n",
    "    # print(\"xTrain: \", xTrain.shape)\n",
    "    # print(\"yTrain: \", yTrain.shape)\n",
    "    # print(\"xVal: \", xVal.shape)\n",
    "    # print(\"yVal: \", yVal.shape)\n",
    "\n",
    "    # Choose optimum model on trainig data\n",
    "\n",
    "    if(learning):\n",
    "      print(\"Learning Model\")\n",
    "      clf = GridSearchCV(estimator=linear_model.LogisticRegression(random_state=0), param_grid=parameter_candidates_log_reg, n_jobs=-1, scoring=\"f1_macro\")\n",
    "      clf.fit(xTrain, yTrain)\n",
    "      clf = clf.best_estimator_\n",
    "      print(\"Optimum C: \", clf.C)\n",
    "    else:\n",
    "      print(\"Using default LR Model\")\n",
    "      clf = linear_model.LogisticRegression(random_state=0)\n",
    "      clf.fit(xTrain, yTrain)\n",
    "\n",
    "    # Predict the validation values\n",
    "    yPred = clf.predict(xVal)\n",
    "\n",
    "    # PLot the values\n",
    "#     plt.hist([yPred, yVal], align='left', rwidth=0.5, label=['Predicted', 'Actual'])\n",
    "#     plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(yVal, yPred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    kappa = cohen_kappa_score(yVal, yPred)\n",
    "    kappas.append(kappa)\n",
    "\n",
    "    # Compute macro metrics\n",
    "    macro['f1'].append(f1_score(yVal, yPred, average=\"macro\"))\n",
    "    macro['recall'].append(recall_score(yVal, yPred, average=\"macro\"))\n",
    "    macro['precision'].append(precision_score(yVal, yPred, average=\"macro\"))\n",
    "\n",
    "    # Compute micro metrics\n",
    "    micro['f1'].append(f1_score(yVal, yPred, average=\"micro\"))\n",
    "    micro['recall'].append(recall_score(yVal, yPred, average=\"micro\"))\n",
    "    micro['precision'].append(precision_score(yVal, yPred, average=\"micro\"))\n",
    "\n",
    "  if(learning):\n",
    "    learnedVsDefault['learned'] = {'micro': micro, 'macro': macro, 'accuracies': accuracies, 'kappas': kappas}\n",
    "    learning = False\n",
    "  else:\n",
    "    learnedVsDefault['default'] = {'micro': micro, 'macro': macro, 'accuracies': accuracies, 'kappas': kappas}\n",
    "    learning = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.011428261929263939, 0.21220677671589916, 0.12249611723945675, 0.18418042163752235, 0.25550344827586202, 0.15232282427329413, 0.18220049352966383, 0.33547815754369048, 0.23614345598509545, 0.20719888063054381]\n",
      "0.162888422486\n",
      "[0.40000000000000002, 0.52307692307692311, 0.42051282051282052, 0.50769230769230766, 0.55641025641025643, 0.49230769230769234, 0.53589743589743588, 0.61025641025641031, 0.57948717948717954, 0.58549222797927458]\n",
      "0.130791017858\n",
      "\n",
      "\n",
      "Learning =  True\n",
      "Average kappa:  0.189915883776 +/- 0.162888422486\n",
      "Average accuracy:  0.521113325362 +/- 0.162888422486\n",
      "\n",
      "Macro\n",
      "f1   0.229172914028 +/- 0.106509976733\n",
      "precision   0.331209227807 +/- 0.203241172056\n",
      "recall   0.236020528319 +/- 0.0919233809651\n",
      "\n",
      "Micro\n",
      "f1   0.521113325362 +/- 0.130791017858\n",
      "precision   0.521113325362 +/- 0.130791017858\n",
      "recall   0.521113325362 +/- 0.130791017858\n",
      "\n",
      "\n",
      "[0.0091052832451883337, 0.18854441273230349, 0.12323648135566123, 0.15775221555814145, 0.23150157197892218, 0.1488470525990917, 0.15976662124864616, 0.28842667031576052, 0.25887821055944227, 0.17488515361533752]\n",
      "0.147895762544\n",
      "[0.40256410256410258, 0.51025641025641022, 0.42307692307692307, 0.50512820512820511, 0.54358974358974355, 0.49230769230769234, 0.52564102564102566, 0.58974358974358976, 0.59743589743589742, 0.58290155440414504]\n",
      "0.125855162792\n",
      "\n",
      "\n",
      "Learning =  False\n",
      "Average kappa:  0.174094367321 +/- 0.147895762544\n",
      "Average accuracy:  0.517264514415 +/- 0.147895762544\n",
      "\n",
      "Macro\n",
      "f1   0.212379847339 +/- 0.0883231445687\n",
      "precision   0.351946946574 +/- 0.157279915931\n",
      "recall   0.223887487022 +/- 0.0667859964097\n",
      "\n",
      "Micro\n",
      "f1   0.517264514415 +/- 0.125855162792\n",
      "precision   0.517264514415 +/- 0.125855162792\n",
      "recall   0.517264514415 +/- 0.125855162792\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(2):\n",
    "    if(learning):\n",
    "        key = 'learned'\n",
    "        learning = False\n",
    "    else:\n",
    "        key = 'default'\n",
    "        learning = True\n",
    "\n",
    "    accuracies = learnedVsDefault[key]['accuracies']\n",
    "    kappas = learnedVsDefault[key]['kappas']\n",
    "    macro = learnedVsDefault[key]['macro']\n",
    "    micro = learnedVsDefault[key]['micro']\n",
    "    \n",
    "    print(kappas)\n",
    "    print(2 * (np.std(kappas)))\n",
    "\n",
    "    print(accuracies)\n",
    "    print(2*(np.std(accuracies)))\n",
    "    \n",
    "    print(\"\\n\\nLearning = \", not learning)\n",
    "    print(\"Average kappa: \", np.mean(kappas), \"+/-\", 2*np.std(kappas))\n",
    "    print(\"Average accuracy: \", np.mean(accuracies),  \"+/-\", 2*np.std(kappas))\n",
    "\n",
    "    print(\"\\nMacro\")\n",
    "    for key, value in macro.items():\n",
    "        print(key, \" \", np.mean(value), \"+/-\", 2*np.std(value))\n",
    "\n",
    "    print(\"\\nMicro\")\n",
    "    for key, value in micro.items():\n",
    "        print(key, \" \", np.mean(value), \"+/-\", 2*np.std(value))\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned = learnedVsDefault['learned']\n",
    "default = learnedVsDefault['default']\n",
    "\n",
    "\n",
    "\n",
    "learnedMetrics = [np.mean(learned['accuracies']), np.mean(learned['kappas'])]\n",
    "for (key, val) in learned['macro'].items():\n",
    "    learnedMetrics.append(np.mean((val)))\n",
    "\n",
    "print(learnedMetrics)\n",
    "\n",
    "defaultMetrics = [np.mean(default['accuracies']), np.mean(default['kappas'])]\n",
    "for (key, val) in default['macro'].items():\n",
    "    defaultMetrics.append(np.mean(val))\n",
    "    \n",
    "print(defaultMetrics)\n",
    "\n",
    "\n",
    "plt.xticks([1,2,3,4,5], ['Accuracy', 'Kappa', 'F1', 'Precision', 'Recall'])\n",
    "plt.bar([1, 2, 3, 4, 5], learnedMetrics, label=\"Learned\", alpha=1)\n",
    "plt.bar([1, 2, 3, 4, 5], defaultMetrics, label=\"Default\", alpha=1)\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
